{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iRjddwOiWzr5"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# load some utilities (for loading MNIST and plotting)\n",
    "# also imports most Python modules\n",
    "%run utils.py\n",
    "\n",
    "# load all MNIST images and labels\n",
    "train_images, train_labels = MNIST()\n",
    "test_images, test_labels = MNIST(test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wjyOyZDn6rk2"
   },
   "source": [
    "# PCA\n",
    "\n",
    "A common method for dimensionality-reduction and feature extraction is the so-called prinicipal component analysis (PCA). Roughly speaking, we focus on the $k$ orthogonal directions in which we observe the largest variation and neglect all other dimensions. In this notebook we try to perform and analyse PCA of the MNIST image data set with $k = 2$ principal components.\n",
    "\n",
    "Let $\\mathbf{X} \\in [0,1]^{N \\times 784}$ be a matrix of the MNIST training data set with $N = 60000$, where each row represents a training image. Moreover, let $\\mathbf{X} - \\overline{\\mathbf{x}}^\\intercal = \\mathbf{U} \\mathbf{\\Sigma} \\mathbf{V}^\\intercal$ be the singular value decomposition of the centered MNIST training data, where $\\overline{\\mathbf{x}} = \\frac{1}{N} \\sum_{i=1}^N \\mathbf{x}_i$.\n",
    "\n",
    "We compute the singular value decomposition $\\mathbf{U} \\boldsymbol{\\Sigma} \\mathbf{V}^\\intercal$ with the function [`torch.svd`](https://pytorch.org/docs/stable/torch.html#torch.svd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wkfNjs3XbMyC"
   },
   "outputs": [],
   "source": [
    "# center training images\n",
    "train_mean = train_images.mean(dim=0, keepdim=True)\n",
    "train_images_centered = train_images - train_mean\n",
    "\n",
    "U, S, V = torch.svd(train_images_centered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0FEQ17jSbMyO"
   },
   "source": [
    "In the preparation exercises, we have discussed how this singular value decomposition can be used to compute the encodings in the principal subspace in a general setting. We apply these results now to the MNIST image data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g9Jt2du7O4z1"
   },
   "source": [
    "## Task 1\n",
    "\n",
    "Compute the encoding `train_encoding` $\\in \\mathbb{R}^{60000 \\times 2}$ and `test_encoding` $\\in \\mathbb{R}^{10000 \\times 2}$ of the images in the MNIST training and the test data set in the two-dimensional principal subspace of the MNIST training images with the help of $\\mathbf{U}$, $\\boldsymbol{\\Sigma}$, and $\\mathbf{V}$.\n",
    "\n",
    "*Hint*: As shown in the introductory notebook, you can compute the product $\\mathbf{A} \\mathbf{B}$ of two PyTorch matrices $\\mathbf{A}$ and $\\mathbf{B}$ with [`A.mm(B)`](https://pytorch.org/docs/stable/torch.html#torch.mm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoding = # WRITE YOUR CODE HERE\n",
    "test_encoding = # WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QqA3hX3ybMyZ"
   },
   "source": [
    "We can inspect the distribution of encodings `train_encoding` and `test_encoding` in the latent space visually with `plot_MNIST_encoding`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "id": "XnA0MGjBbMyc",
    "outputId": "bd846c81-c8af-41e4-eebf-62f8126f3333"
   },
   "outputs": [],
   "source": [
    "plot_encoding((train_encoding, train_labels), (test_encoding, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rqr1928yo9M0"
   },
   "source": [
    "We can investigate the encodings of the images in the MNIST training data for each of the digits $0, 1, \\ldots, 9$ separately. For instance, we can compute the mean encoding for each digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "colab_type": "code",
    "id": "gaQ3kMUkoYel",
    "outputId": "bce2e63b-283f-459e-a312-90274f90fd82"
   },
   "outputs": [],
   "source": [
    "# compute mean encoding\n",
    "train_mean_encodings = mean_encodings(train_encoding, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These mean encodings are just the mean vector of the different clusters that the encodings of the training images form in the principal subspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_encoding((train_encoding, train_labels), (test_encoding, test_labels),\n",
    "              train_mean_encodings, annotate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these encodings we can reconstruct images, using the formula provided in the preparation exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "colab_type": "code",
    "id": "gaQ3kMUkoYel",
    "outputId": "bce2e63b-283f-459e-a312-90274f90fd82"
   },
   "outputs": [],
   "source": [
    "# compute mean images\n",
    "train_mean_images = train_mean + train_mean_encodings.mm(V[:, :2].t())\n",
    "\n",
    "plot_images(train_mean_images, torch.arange(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4E2osmkbwacw"
   },
   "source": [
    "We can investigate the latent space a bit more. Let us build a grid of points that is spanned by the mean encodings for digit \"0\" and digit \"9\" in the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "colab_type": "code",
    "id": "VP1UTE1Vt7lz",
    "outputId": "83e67f14-40eb-46a6-e743-0c0b278aa019"
   },
   "outputs": [],
   "source": [
    "# compute grid of latent vectors\n",
    "zgrid = create_grid(train_mean_encodings[0], train_mean_encodings[9])\n",
    "\n",
    "# visualize it\n",
    "plot_encoding((train_encoding, train_labels), (test_encoding, test_labels), zgrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we reconstruct and plot the images corresponding to these encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "colab_type": "code",
    "id": "VP1UTE1Vt7lz",
    "outputId": "83e67f14-40eb-46a6-e743-0c0b278aa019"
   },
   "outputs": [],
   "source": [
    "# compute mean images\n",
    "xgrid = train_mean + zgrid.mm(V[:, :2].t())\n",
    "\n",
    "plot_images(xgrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QjsGYI6pbMyt"
   },
   "source": [
    "We turn back to the MNIST data set.\n",
    "\n",
    "## Task 2\n",
    "\n",
    "Compute the reconstruction `test_reconstruction` $\\in \\mathbb{R}^{10000 \\times 784}$ of the images in the MNIST test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_reconstruction = # WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QjtEPRQnbMyv"
   },
   "source": [
    "We plot some test images and their reconstructed counterparts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 594
    },
    "colab_type": "code",
    "id": "pVhQvVPmbMyy",
    "outputId": "8eb23df7-62db-489b-9050-a5d6be658f6d"
   },
   "outputs": [],
   "source": [
    "plot_reconstruction(test_images, test_reconstruction, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comparison of the original images and their reconstructions provides us with some intuition for how much information is lost by the compression of the images to the two-dimensional latent space. As a less subjective measure we calculate the average squared reconstruction error\n",
    "\\begin{equation*}\n",
    "\\mathrm{sqerr} := \\frac{1}{10000} \\|\\mathbf{x}_i - \\tilde{\\mathbf{x}}_i\\|^2_2\n",
    "\\end{equation*}\n",
    "of the images $\\mathbf{x}_i \\in {[0,1]}^{784}$ and their reconstruction $\\tilde{\\mathbf{x}}_i \\in \\mathbb{R}^{784}$ ($i = 1,\\ldots, 10000$) in the MNIST test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ho3lBFIyaKg6",
    "outputId": "2bd47fa7-016c-46a5-a33e-45428438cd46"
   },
   "outputs": [],
   "source": [
    "sqerr = (test_images - test_reconstruction).pow(2).sum(dim=1).mean()\n",
    "print(f\"Average squared reconstruction error: {sqerr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An advantage of an objective measure such as the average squared reconstruction error is that it enables us to compare the PCA with other models for dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Answer Questions 4.1 and 4.2 in the lab instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this first part of the lab session, we have seen how we can extract the two components from the MNIST images of hand-written digits that cause the largest variations in the data set. We can encode any such image (even from the test data set) by mapping it to the principal subspace, and we are able to produce a lossy reconstruction of the images. We generated even some new images, but only on a grid of points that we extracted from the encodings of the training data. In the next part of the lab we will work with a probabilistic model that allows us to sample new images in a more general way."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "colab": {
   "name": "PCA.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
